WarpDrive not installed or not fully importable (likely missing pycuda). Using custom CPU trainer.
WARNING: CUDA or WarpDrive not available. Falling back to Custom CPU Training.
CPU Mode: Reduced agents to 200 and iterations to 5000
Loading checkpoint from latest_checkpoint.pth
Checkpoint loaded successfully.
Starting Iteration 0
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 0: Reward -45.440 Loss 32458.553 AE 0.050
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 1
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 1: Reward -55.894 Loss 62952.148 AE 0.061
Starting Iteration 2
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 2: Reward -46.167 Loss 38833.836 AE 0.058
Starting Iteration 3
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 3: Reward -50.233 Loss 72738.539 AE 0.056
Starting Iteration 4
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 4: Reward -51.906 Loss 51489.957 AE 0.056
Starting Iteration 5
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 5: Reward -55.182 Loss 53046.969 AE 0.055
Starting Iteration 6
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 6: Reward -51.750 Loss 43939.246 AE 0.053
Starting Iteration 7
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 7: Reward -54.158 Loss 54648.902 AE 0.055
Starting Iteration 8
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 8: Reward -51.371 Loss 41185.047 AE 0.054
Starting Iteration 9
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 9: Reward -50.327 Loss 43139.594 AE 0.054
Starting Iteration 10
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 10: Reward -46.740 Loss 44932.922 AE 0.053
Starting Iteration 11
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 11: Reward -49.591 Loss 79909.484 AE 0.053
Starting Iteration 12
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 12: Reward -51.055 Loss 46276.801 AE 0.053
Starting Iteration 13
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 13: Reward -50.716 Loss 44508.949 AE 0.052
Starting Iteration 14
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 14: Reward -57.822 Loss 54946.539 AE 0.053
Starting Iteration 15
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 15: Reward -50.200 Loss 43772.930 AE 0.052
Starting Iteration 16
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 16: Reward -47.157 Loss 39364.098 AE 0.052
Starting Iteration 17
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 17: Reward -52.963 Loss 137743.734 AE 0.051
Starting Iteration 18
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 18: Reward -54.255 Loss 50966.090 AE 0.051
Starting Iteration 19
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 19: Reward -44.391 Loss 37047.328 AE 0.051
Starting Iteration 20
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 20: Reward -52.983 Loss 48353.230 AE 0.051
Starting Iteration 21
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 21: Reward -46.472 Loss 38332.008 AE 0.051
Starting Iteration 22
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 22: Reward -51.998 Loss 95314.984 AE 0.051
Starting Iteration 23
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 23: Reward -53.075 Loss 50210.887 AE 0.051
Starting Iteration 24
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 24: Reward -50.224 Loss 41915.598 AE 0.051
Starting Iteration 25
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 25: Reward -55.602 Loss 60736.328 AE 0.050
Starting Iteration 26
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 26: Reward -51.010 Loss 50096.199 AE 0.051
Starting Iteration 27
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 27: Reward -50.615 Loss 43639.176 AE 0.050
Starting Iteration 28
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 28: Reward -57.356 Loss 65465.703 AE 0.051
Starting Iteration 29
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 29: Reward -54.771 Loss 47410.715 AE 0.051
Starting Iteration 30
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 30: Reward -52.787 Loss 52293.848 AE 0.050
Starting Iteration 31
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 31: Reward -49.706 Loss 37954.641 AE 0.050
Starting Iteration 32
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 32: Reward -53.717 Loss 43058.793 AE 0.050
Starting Iteration 33
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 33: Reward -47.480 Loss 42739.102 AE 0.050
Starting Iteration 34
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 34: Reward -47.995 Loss 39313.359 AE 0.050
Starting Iteration 35
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 35: Reward -56.524 Loss 58564.277 AE 0.049
Starting Iteration 36
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 36: Reward -54.395 Loss 50400.684 AE 0.050
Starting Iteration 37
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 37: Reward -50.942 Loss 37861.414 AE 0.050
Starting Iteration 38
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 38: Reward -54.187 Loss 226268.188 AE 0.050
Starting Iteration 39
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 39: Reward -49.234 Loss 37939.105 AE 0.050
Starting Iteration 40
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 40: Reward -49.586 Loss 44964.969 AE 0.050
Starting Iteration 41
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 41: Reward -50.015 Loss 42867.848 AE 0.049
Starting Iteration 42
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 42: Reward -53.225 Loss 47581.102 AE 0.050
Starting Iteration 43
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 43: Reward -54.520 Loss 53552.922 AE 0.050
Starting Iteration 44
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 44: Reward -51.033 Loss 38578.250 AE 0.050
Starting Iteration 45
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 45: Reward -48.546 Loss 38085.664 AE 0.049
Starting Iteration 46
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 46: Reward -46.973 Loss 37608.609 AE 0.050
Starting Iteration 47
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 47: Reward -53.366 Loss 43346.531 AE 0.050
Starting Iteration 48
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 48: Reward -54.655 Loss 50383.258 AE 0.050
Starting Iteration 49
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 49: Reward -53.618 Loss 50211.484 AE 0.049
Starting Iteration 50
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 50: Reward -52.557 Loss 44268.375 AE 0.050
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 51
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 51: Reward -51.753 Loss 63749.359 AE 0.049
Starting Iteration 52
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 52: Reward -59.475 Loss 204460.281 AE 0.049
Starting Iteration 53
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 53: Reward -55.539 Loss 50664.855 AE 0.049
Starting Iteration 54
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 54: Reward -53.974 Loss 51688.051 AE 0.049
Starting Iteration 55
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 55: Reward -52.596 Loss 51099.953 AE 0.050
Starting Iteration 56
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 56: Reward -49.909 Loss 37469.203 AE 0.049
Starting Iteration 57
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 57: Reward -54.231 Loss 43694.809 AE 0.049
Starting Iteration 58
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 58: Reward -48.075 Loss 44977.598 AE 0.049
Starting Iteration 59
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 59: Reward -53.702 Loss 48975.129 AE 0.049
Starting Iteration 60
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 60: Reward -48.116 Loss 36437.902 AE 0.049
Starting Iteration 61
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 61: Reward -53.176 Loss 54274.559 AE 0.049
Starting Iteration 62
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 62: Reward -46.381 Loss 34186.828 AE 0.049
Starting Iteration 63
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 63: Reward -48.033 Loss 80381.773 AE 0.050
Starting Iteration 64
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 64: Reward -52.757 Loss 46623.422 AE 0.050
Starting Iteration 65
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 65: Reward -56.207 Loss 56089.832 AE 0.050
Starting Iteration 66
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 66: Reward -55.367 Loss 41447.473 AE 0.050
Starting Iteration 67
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 67: Reward -54.297 Loss 50193.453 AE 0.050
Starting Iteration 68
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 68: Reward -55.611 Loss 46113.816 AE 0.049
Starting Iteration 69
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 69: Reward -57.119 Loss 75798.625 AE 0.050
Starting Iteration 70
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 70: Reward -46.983 Loss 32997.227 AE 0.050
Starting Iteration 71
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 71: Reward -47.767 Loss 59755.375 AE 0.050
Starting Iteration 72
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 72: Reward -55.268 Loss 46789.512 AE 0.050
Starting Iteration 73
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 73: Reward -51.426 Loss 43805.539 AE 0.050
Starting Iteration 74
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 74: Reward -57.793 Loss 53381.320 AE 0.050
Starting Iteration 75
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 75: Reward -48.442 Loss 38901.887 AE 0.050
Starting Iteration 76
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 76: Reward -54.585 Loss 46523.453 AE 0.050
Starting Iteration 77
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 77: Reward -61.261 Loss 50864.641 AE 0.050
Starting Iteration 78
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 78: Reward -52.202 Loss 41677.926 AE 0.050
Starting Iteration 79
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 79: Reward -47.365 Loss 33118.355 AE 0.050
Starting Iteration 80
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 80: Reward -50.838 Loss 37963.281 AE 0.050
Starting Iteration 81
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 81: Reward -50.634 Loss 69992.883 AE 0.050
Starting Iteration 82
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 82: Reward -54.343 Loss 50600.871 AE 0.050
Starting Iteration 83
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 83: Reward -56.174 Loss 49463.145 AE 0.050
Starting Iteration 84
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 84: Reward -49.928 Loss 43666.879 AE 0.050
Starting Iteration 85
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 85: Reward -57.082 Loss 54330.711 AE 0.050
Starting Iteration 86
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 86: Reward -46.906 Loss 54450.512 AE 0.050
Starting Iteration 87
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 87: Reward -43.610 Loss 31938.945 AE 0.049
Starting Iteration 88
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 88: Reward -53.804 Loss 45686.543 AE 0.050
Starting Iteration 89
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 89: Reward -50.930 Loss 41302.238 AE 0.049
Starting Iteration 90
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 90: Reward -50.021 Loss 39508.750 AE 0.049
Starting Iteration 91
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 91: Reward -45.481 Loss 37212.059 AE 0.049
Starting Iteration 92
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 92: Reward -52.145 Loss 46517.473 AE 0.050
Starting Iteration 93
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 93: Reward -48.711 Loss 41160.023 AE 0.049
Starting Iteration 94
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 94: Reward -47.710 Loss 38161.863 AE 0.049
Starting Iteration 95
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 95: Reward -51.280 Loss 41590.477 AE 0.049
Starting Iteration 96
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 96: Reward -53.817 Loss 47569.305 AE 0.049
Starting Iteration 97
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 97: Reward -47.887 Loss 48992.102 AE 0.050
Starting Iteration 98
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 98: Reward -47.042 Loss 39769.336 AE 0.049
Starting Iteration 99
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 99: Reward -58.653 Loss 57773.172 AE 0.050
Starting Iteration 100
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 100: Reward -48.520 Loss 51985.176 AE 0.049
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 101
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 101: Reward -52.187 Loss 43254.207 AE 0.049
Starting Iteration 102
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 102: Reward -47.381 Loss 42902.938 AE 0.050
Starting Iteration 103
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 103: Reward -49.600 Loss 42535.711 AE 0.049
Starting Iteration 104
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 104: Reward -47.034 Loss 32860.336 AE 0.050
Starting Iteration 105
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 105: Reward -49.131 Loss 33536.727 AE 0.050
Starting Iteration 106
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 106: Reward -51.068 Loss 42334.137 AE 0.050
Starting Iteration 107
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 107: Reward -53.917 Loss 42669.812 AE 0.050
Starting Iteration 108
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 108: Reward -50.455 Loss 46520.984 AE 0.049
Starting Iteration 109
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 109: Reward -56.963 Loss 64328.457 AE 0.049
Starting Iteration 110
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 110: Reward -54.268 Loss 69539.203 AE 0.049
Starting Iteration 111
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 111: Reward -49.301 Loss 41077.246 AE 0.049
Starting Iteration 112
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 112: Reward -53.370 Loss 49338.062 AE 0.049
Starting Iteration 113
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 113: Reward -57.580 Loss 63789.016 AE 0.050
Starting Iteration 114
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 114: Reward -47.146 Loss 38928.461 AE 0.049
Starting Iteration 115
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 115: Reward -53.263 Loss 44982.027 AE 0.050
Starting Iteration 116
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 116: Reward -44.515 Loss 34085.082 AE 0.049
Starting Iteration 117
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 117: Reward -56.786 Loss 43485.711 AE 0.050
Starting Iteration 118
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 118: Reward -54.186 Loss 42729.348 AE 0.049
Starting Iteration 119
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 119: Reward -56.822 Loss 46228.344 AE 0.049
Starting Iteration 120
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 120: Reward -53.657 Loss 54775.746 AE 0.049
Starting Iteration 121
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 121: Reward -55.318 Loss 53064.547 AE 0.049
Starting Iteration 122
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 122: Reward -50.436 Loss 39710.641 AE 0.048
Starting Iteration 123
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 123: Reward -47.969 Loss 40689.352 AE 0.049
Starting Iteration 124
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 124: Reward -46.606 Loss 36854.535 AE 0.049
Starting Iteration 125
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 125: Reward -50.694 Loss 36849.438 AE 0.048
Starting Iteration 126
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 126: Reward -51.270 Loss 34663.930 AE 0.048
Starting Iteration 127
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 127: Reward -55.738 Loss 39845.570 AE 0.048
Starting Iteration 128
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 128: Reward -53.806 Loss 35090.637 AE 0.048
Starting Iteration 129
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 129: Reward -50.584 Loss 40303.184 AE 0.049
Starting Iteration 130
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 130: Reward -49.386 Loss 36637.215 AE 0.049
Starting Iteration 131
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 131: Reward -55.144 Loss 47125.508 AE 0.049
Starting Iteration 132
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 132: Reward -55.221 Loss 46085.633 AE 0.049
Starting Iteration 133
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 133: Reward -51.748 Loss 44466.078 AE 0.049
Starting Iteration 134
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 134: Reward -52.989 Loss 50283.672 AE 0.049
Starting Iteration 135
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 135: Reward -54.610 Loss 55475.953 AE 0.049
Starting Iteration 136
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 136: Reward -51.076 Loss 45978.418 AE 0.049
Starting Iteration 137
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 137: Reward -49.369 Loss 46113.215 AE 0.049
Starting Iteration 138
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 138: Reward -49.471 Loss 39644.680 AE 0.049
Starting Iteration 139
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 139: Reward -56.379 Loss 57205.293 AE 0.050
Starting Iteration 140
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 140: Reward -53.321 Loss 38035.035 AE 0.049
Starting Iteration 141
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 141: Reward -52.855 Loss 47350.832 AE 0.049
Starting Iteration 142
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 142: Reward -59.022 Loss 42860.656 AE 0.049
Starting Iteration 143
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 143: Reward -51.764 Loss 45418.516 AE 0.049
Starting Iteration 144
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 144: Reward -54.615 Loss 44155.746 AE 0.050
Starting Iteration 145
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 145: Reward -55.913 Loss 84601.797 AE 0.049
Starting Iteration 146
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 146: Reward -47.989 Loss 38645.824 AE 0.049
Starting Iteration 147
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 147: Reward -56.078 Loss 198869.781 AE 0.049
Starting Iteration 148
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 148: Reward -48.372 Loss 40249.012 AE 0.048
Starting Iteration 149
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 149: Reward -52.070 Loss 47022.281 AE 0.049
Starting Iteration 150
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 150: Reward -49.963 Loss 35392.355 AE 0.048
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 151
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 151: Reward -48.571 Loss 41957.699 AE 0.048
Starting Iteration 152
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 152: Reward -49.115 Loss 44511.715 AE 0.046
Starting Iteration 153
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 153: Reward -54.564 Loss 46341.898 AE 0.047
Starting Iteration 154
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 154: Reward -52.447 Loss 41992.258 AE 0.048
Starting Iteration 155
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 155: Reward -52.858 Loss 41829.371 AE 0.049
Starting Iteration 156
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 156: Reward -51.479 Loss 43169.199 AE 0.049
Starting Iteration 157
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 157: Reward -52.349 Loss 40840.062 AE 0.049
Starting Iteration 158
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 158: Reward -52.786 Loss 63665.520 AE 0.049
Starting Iteration 159
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 159: Reward -49.099 Loss 40315.723 AE 0.050
Starting Iteration 160
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 160: Reward -49.102 Loss 37159.441 AE 0.050
Starting Iteration 161
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 161: Reward -55.157 Loss 74674.570 AE 0.050
Starting Iteration 162
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 162: Reward -49.191 Loss 38729.973 AE 0.049
Starting Iteration 163
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 163: Reward -56.882 Loss 46207.215 AE 0.050
Starting Iteration 164
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 164: Reward -50.377 Loss 43002.262 AE 0.050
Starting Iteration 165
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 165: Reward -48.568 Loss 33958.449 AE 0.050
Starting Iteration 166
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 166: Reward -51.846 Loss 46122.375 AE 0.050
Starting Iteration 167
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 167: Reward -54.713 Loss 48600.246 AE 0.050
Starting Iteration 168
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 168: Reward -49.119 Loss 42600.152 AE 0.050
Starting Iteration 169
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 169: Reward -45.209 Loss 39822.766 AE 0.050
Starting Iteration 170
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 170: Reward -52.795 Loss 158847.297 AE 0.049
Starting Iteration 171
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 171: Reward -51.069 Loss 38571.492 AE 0.049
Starting Iteration 172
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 172: Reward -51.490 Loss 50839.691 AE 0.050
Starting Iteration 173
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 173: Reward -49.296 Loss 39056.508 AE 0.050
Starting Iteration 174
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 174: Reward -52.247 Loss 36116.789 AE 0.050
Starting Iteration 175
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 175: Reward -48.648 Loss 33352.844 AE 0.050
Starting Iteration 176
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 176: Reward -54.922 Loss 43855.113 AE 0.050
Starting Iteration 177
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 177: Reward -52.750 Loss 52986.094 AE 0.050
Starting Iteration 178
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 178: Reward -48.193 Loss 31638.904 AE 0.050
Starting Iteration 179
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 179: Reward -53.329 Loss 46511.707 AE 0.050
Starting Iteration 180
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 180: Reward -55.311 Loss 50202.535 AE 0.049
Starting Iteration 181
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 181: Reward -56.645 Loss 50028.520 AE 0.050
Starting Iteration 182
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 182: Reward -53.255 Loss 48304.207 AE 0.050
Starting Iteration 183
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 183: Reward -58.039 Loss 58167.023 AE 0.050
Starting Iteration 184
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 184: Reward -55.949 Loss 97907.367 AE 0.050
Starting Iteration 185
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 185: Reward -57.484 Loss 52626.793 AE 0.050
Starting Iteration 186
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 186: Reward -49.004 Loss 35945.812 AE 0.050
Starting Iteration 187
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 187: Reward -46.810 Loss 33636.297 AE 0.050
Starting Iteration 188
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 188: Reward -54.253 Loss 45796.066 AE 0.050
Starting Iteration 189
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 189: Reward -52.768 Loss 36236.527 AE 0.050
Starting Iteration 190
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 190: Reward -46.125 Loss 36550.617 AE 0.050
Starting Iteration 191
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 191: Reward -51.098 Loss 43248.848 AE 0.050
Starting Iteration 192
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 192: Reward -47.862 Loss 34774.508 AE 0.050
Starting Iteration 193
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 193: Reward -46.423 Loss 33114.066 AE 0.050
Starting Iteration 194
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 194: Reward -48.330 Loss 37059.367 AE 0.050
Starting Iteration 195
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 195: Reward -54.444 Loss 39904.223 AE 0.050
Starting Iteration 196
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 196: Reward -52.620 Loss 37847.496 AE 0.050
Starting Iteration 197
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 197: Reward -45.939 Loss 28973.205 AE 0.049
Starting Iteration 198
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 198: Reward -51.164 Loss 39279.266 AE 0.049
Starting Iteration 199
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 199: Reward -55.860 Loss 44160.645 AE 0.050
Starting Iteration 200
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 200: Reward -52.068 Loss 38092.289 AE 0.049
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 201
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 201: Reward -55.543 Loss 41460.496 AE 0.050
Starting Iteration 202
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 202: Reward -47.413 Loss 35118.441 AE 0.050
Starting Iteration 203
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 203: Reward -51.210 Loss 35274.926 AE 0.050
Starting Iteration 204
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 204: Reward -56.055 Loss 42536.645 AE 0.050
Starting Iteration 205
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 205: Reward -51.661 Loss 38360.715 AE 0.050
Starting Iteration 206
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 206: Reward -54.181 Loss 39814.781 AE 0.050
Starting Iteration 207
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 207: Reward -54.466 Loss 43400.750 AE 0.050
Starting Iteration 208
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 208: Reward -51.859 Loss 50837.715 AE 0.051
Starting Iteration 209
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 209: Reward -47.350 Loss 40630.367 AE 0.050
Starting Iteration 210
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 210: Reward -55.881 Loss 45420.863 AE 0.050
Starting Iteration 211
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 211: Reward -58.341 Loss 43981.309 AE 0.050
Starting Iteration 212
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 212: Reward -50.588 Loss 37559.473 AE 0.050
Starting Iteration 213
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 213: Reward -53.243 Loss 51844.609 AE 0.050
Starting Iteration 214
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 214: Reward -55.711 Loss 110645.047 AE 0.050
Starting Iteration 215
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 215: Reward -57.619 Loss 47486.676 AE 0.049
Starting Iteration 216
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 216: Reward -48.660 Loss 121644.898 AE 0.050
Starting Iteration 217
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 217: Reward -51.611 Loss 48319.082 AE 0.050
Starting Iteration 218
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 218: Reward -52.498 Loss 40231.754 AE 0.050
Starting Iteration 219
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 219: Reward -54.077 Loss 41505.676 AE 0.050
Starting Iteration 220
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 220: Reward -48.725 Loss 34736.262 AE 0.050
Starting Iteration 221
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 221: Reward -55.410 Loss 43324.562 AE 0.049
Starting Iteration 222
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 222: Reward -50.020 Loss 35823.383 AE 0.050
Starting Iteration 223
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 223: Reward -50.669 Loss 36491.441 AE 0.049
Starting Iteration 224
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 224: Reward -60.582 Loss 44563.188 AE 0.049
Starting Iteration 225
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 225: Reward -45.051 Loss 36401.582 AE 0.049
Starting Iteration 226
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 226: Reward -50.131 Loss 44785.789 AE 0.049
Starting Iteration 227
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 227: Reward -47.666 Loss 38964.582 AE 0.049
Starting Iteration 228
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 228: Reward -54.802 Loss 51549.891 AE 0.049
Starting Iteration 229
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 229: Reward -60.243 Loss 197742.078 AE 0.049
Starting Iteration 230
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 230: Reward -55.888 Loss 43468.078 AE 0.049
Starting Iteration 231
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 231: Reward -55.342 Loss 37817.148 AE 0.050
Starting Iteration 232
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 232: Reward -57.158 Loss 161484.984 AE 0.050
Starting Iteration 233
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 233: Reward -58.766 Loss 59910.004 AE 0.050
Starting Iteration 234
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 234: Reward -57.440 Loss 83186.930 AE 0.049
Starting Iteration 235
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 235: Reward -54.112 Loss 102764.820 AE 0.049
Starting Iteration 236
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 236: Reward -59.825 Loss 66271.602 AE 0.050
Starting Iteration 237
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 237: Reward -47.209 Loss 37146.176 AE 0.049
Starting Iteration 238
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 238: Reward -48.871 Loss 34884.586 AE 0.050
Starting Iteration 239
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 239: Reward -52.130 Loss 48785.898 AE 0.050
Starting Iteration 240
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 240: Reward -50.366 Loss 44538.824 AE 0.049
Starting Iteration 241
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 241: Reward -50.147 Loss 34341.387 AE 0.050
Starting Iteration 242
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 242: Reward -50.923 Loss 37935.766 AE 0.050
Starting Iteration 243
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 243: Reward -52.749 Loss 39787.535 AE 0.049
Starting Iteration 244
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 244: Reward -54.664 Loss 34833.227 AE 0.049
Starting Iteration 245
  Step 0/20