WarpDrive not installed or not fully importable (likely missing pycuda). Using custom CPU trainer.
WARNING: CUDA or WarpDrive not available. Falling back to Custom CPU Training.
CPU Mode: Reduced agents to 200 and iterations to 5000
Loading checkpoint from latest_checkpoint.pth
Checkpoint loaded successfully.
Starting Iteration 0
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 0: Reward -52.779 Loss 39284.055 AE 0.049
Saved checkpoint to latest_checkpoint.pth
Saved static trajectory image: visualizations/traj_0.png
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 1
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 1: Reward -58.429 Loss 55822.059 AE 0.055
Starting Iteration 2
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 2: Reward -48.239 Loss 31485.229 AE 0.054
Starting Iteration 3
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 3: Reward -52.550 Loss 39576.855 AE 0.053
Starting Iteration 4
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 4: Reward -47.469 Loss 34817.367 AE 0.051
Starting Iteration 5
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 5: Reward -50.684 Loss 38838.684 AE 0.050
Starting Iteration 6
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 6: Reward -48.420 Loss 31544.348 AE 0.049
Starting Iteration 7
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 7: Reward -49.860 Loss 37869.684 AE 0.048
Starting Iteration 8
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 8: Reward -48.009 Loss 30541.150 AE 0.047
Starting Iteration 9
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 9: Reward -49.984 Loss 43205.312 AE 0.046
Starting Iteration 10
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 10: Reward -53.408 Loss 47147.461 AE 0.046
Starting Iteration 11
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 11: Reward -53.341 Loss 37960.031 AE 0.046
Starting Iteration 12
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 12: Reward -50.036 Loss 37290.762 AE 0.046
Starting Iteration 13
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 13: Reward -48.906 Loss 55484.992 AE 0.047
Starting Iteration 14
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 14: Reward -53.693 Loss 41075.414 AE 0.047
Starting Iteration 15
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 15: Reward -47.717 Loss 108856.977 AE 0.047
Starting Iteration 16
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 16: Reward -51.964 Loss 42548.008 AE 0.047
Starting Iteration 17
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 17: Reward -49.646 Loss 36152.629 AE 0.046
Starting Iteration 18
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 18: Reward -46.236 Loss 33420.957 AE 0.045
Starting Iteration 19
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 19: Reward -51.667 Loss 40907.883 AE 0.045
Starting Iteration 20
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 20: Reward -56.274 Loss 86384.766 AE 0.045
Starting Iteration 21
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 21: Reward -54.570 Loss 49527.312 AE 0.044
Starting Iteration 22
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 22: Reward -51.661 Loss 61816.395 AE 0.044
Starting Iteration 23
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 23: Reward -58.513 Loss 58998.633 AE 0.044
Starting Iteration 24
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 24: Reward -47.416 Loss 31863.197 AE 0.045
Starting Iteration 25
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 25: Reward -47.549 Loss 39722.109 AE 0.045
Starting Iteration 26
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 26: Reward -53.695 Loss 48746.484 AE 0.046
Starting Iteration 27
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 27: Reward -47.606 Loss 42132.090 AE 0.046
Starting Iteration 28
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 28: Reward -56.684 Loss 53927.961 AE 0.046
Starting Iteration 29
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 29: Reward -52.272 Loss 42392.965 AE 0.046
Starting Iteration 30
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 30: Reward -52.687 Loss 37597.539 AE 0.046
Starting Iteration 31
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 31: Reward -47.232 Loss 33699.676 AE 0.047
Starting Iteration 32
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 32: Reward -48.083 Loss 32454.193 AE 0.046
Starting Iteration 33
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 33: Reward -44.883 Loss 36192.875 AE 0.047
Starting Iteration 34
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 34: Reward -53.068 Loss 42926.457 AE 0.046
Starting Iteration 35
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 35: Reward -56.550 Loss 46092.234 AE 0.047
Starting Iteration 36
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 36: Reward -54.567 Loss 53309.605 AE 0.047
Starting Iteration 37
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 37: Reward -50.420 Loss 89046.000 AE 0.048
Starting Iteration 38
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 38: Reward -54.519 Loss 38966.020 AE 0.048
Starting Iteration 39
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 39: Reward -53.520 Loss 48851.586 AE 0.048
Starting Iteration 40
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 40: Reward -53.439 Loss 39400.902 AE 0.049
Starting Iteration 41
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 41: Reward -50.237 Loss 44966.426 AE 0.049
Starting Iteration 42
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 42: Reward -56.597 Loss 51506.215 AE 0.049
Starting Iteration 43
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 43: Reward -51.536 Loss 41705.961 AE 0.049
Starting Iteration 44
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 44: Reward -47.730 Loss 40106.180 AE 0.049
Starting Iteration 45
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 45: Reward -55.491 Loss 45645.043 AE 0.049
Starting Iteration 46
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 46: Reward -51.689 Loss 38833.422 AE 0.049
Starting Iteration 47
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 47: Reward -49.784 Loss 35585.609 AE 0.050
Starting Iteration 48
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 48: Reward -45.948 Loss 31663.555 AE 0.050
Starting Iteration 49
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 49: Reward -51.216 Loss 41080.789 AE 0.049
Starting Iteration 50
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 50: Reward -45.786 Loss 33177.734 AE 0.049
Saved checkpoint to latest_checkpoint.pth
Saved static trajectory image: visualizations/traj_50.png
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 51
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 51: Reward -50.019 Loss 48267.855 AE 0.049
Starting Iteration 52
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 52: Reward -53.352 Loss 45583.180 AE 0.049
Starting Iteration 53
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 53: Reward -53.473 Loss 44593.039 AE 0.048
Starting Iteration 54
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 54: Reward -50.788 Loss 143668.391 AE 0.049
Starting Iteration 55
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 55: Reward -54.004 Loss 41738.480 AE 0.048
Starting Iteration 56
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 56: Reward -46.853 Loss 35478.918 AE 0.049
Starting Iteration 57
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 57: Reward -52.065 Loss 38726.457 AE 0.049
Starting Iteration 58
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 58: Reward -50.831 Loss 32864.445 AE 0.049
Starting Iteration 59
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 59: Reward -52.378 Loss 39222.953 AE 0.049
Starting Iteration 60
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 60: Reward -54.411 Loss 46106.344 AE 0.048
Starting Iteration 61
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 61: Reward -59.527 Loss 82820.875 AE 0.049
Starting Iteration 62
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 62: Reward -50.001 Loss 32997.094 AE 0.048
Starting Iteration 63
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 63: Reward -46.039 Loss 75361.250 AE 0.049
Starting Iteration 64
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 64: Reward -45.842 Loss 41244.031 AE 0.049
Starting Iteration 65
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 65: Reward -48.973 Loss 35797.324 AE 0.049
Starting Iteration 66
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 66: Reward -54.818 Loss 43442.746 AE 0.049
Starting Iteration 67
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 67: Reward -50.655 Loss 39007.527 AE 0.049
Starting Iteration 68
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 68: Reward -60.303 Loss 43416.152 AE 0.049
Starting Iteration 69
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 69: Reward -53.441 Loss 48142.387 AE 0.049
Starting Iteration 70
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 70: Reward -48.968 Loss 42866.078 AE 0.048
Starting Iteration 71
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 71: Reward -46.902 Loss 31107.777 AE 0.049
Starting Iteration 72
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 72: Reward -50.321 Loss 31143.178 AE 0.049
Starting Iteration 73
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 73: Reward -52.935 Loss 39026.227 AE 0.049
Starting Iteration 74
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 74: Reward -55.165 Loss 55049.176 AE 0.049
Starting Iteration 75
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 75: Reward -55.488 Loss 59817.730 AE 0.048
Starting Iteration 76
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 76: Reward -52.920 Loss 58526.535 AE 0.049
Starting Iteration 77
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 77: Reward -49.174 Loss 33643.645 AE 0.048
Starting Iteration 78
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 78: Reward -48.704 Loss 35633.055 AE 0.048
Starting Iteration 79
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 79: Reward -51.241 Loss 36096.781 AE 0.048
Starting Iteration 80
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 80: Reward -50.550 Loss 34575.527 AE 0.047
Starting Iteration 81
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 81: Reward -55.237 Loss 43224.566 AE 0.048
Starting Iteration 82
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 82: Reward -50.045 Loss 41533.215 AE 0.047
Starting Iteration 83
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 83: Reward -57.078 Loss 62550.043 AE 0.046
Starting Iteration 84
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 84: Reward -51.947 Loss 35570.266 AE 0.046
Starting Iteration 85
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 85: Reward -52.797 Loss 46965.785 AE 0.046
Starting Iteration 86
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 86: Reward -51.357 Loss 47780.293 AE 0.045
Starting Iteration 87
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 87: Reward -54.104 Loss 43110.262 AE 0.045
Starting Iteration 88
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 88: Reward -56.542 Loss 57499.867 AE 0.046
Starting Iteration 89
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 89: Reward -51.079 Loss 72360.328 AE 0.046
Starting Iteration 90
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 90: Reward -55.424 Loss 66375.484 AE 0.047
Starting Iteration 91
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 91: Reward -52.317 Loss 41057.105 AE 0.046
Starting Iteration 92
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 92: Reward -53.587 Loss 47736.504 AE 0.047
Starting Iteration 93
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 93: Reward -53.232 Loss 37975.695 AE 0.046
Starting Iteration 94
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 94: Reward -50.427 Loss 40427.691 AE 0.046
Starting Iteration 95
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 95: Reward -49.162 Loss 39902.457 AE 0.046
Starting Iteration 96
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 96: Reward -52.733 Loss 41823.027 AE 0.046
Starting Iteration 97
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 97: Reward -51.104 Loss 40141.449 AE 0.046
Starting Iteration 98
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 98: Reward -48.950 Loss 37659.945 AE 0.046
Starting Iteration 99
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 99: Reward -53.141 Loss 38042.973 AE 0.046
Starting Iteration 100
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 100: Reward -58.215 Loss 52145.199 AE 0.046
Saved checkpoint to latest_checkpoint.pth
Saved static trajectory image: visualizations/traj_100.png
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 101
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 101: Reward -53.602 Loss 39518.789 AE 0.045
Starting Iteration 102
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 102: Reward -47.032 Loss 29588.578 AE 0.046
Starting Iteration 103
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 103: Reward -54.391 Loss 51022.148 AE 0.046
Starting Iteration 104
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 104: Reward -48.634 Loss 38123.668 AE 0.046
Starting Iteration 105
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 105: Reward -51.122 Loss 39415.422 AE 0.046
Starting Iteration 106
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 106: Reward -43.725 Loss 26985.482 AE 0.047
Starting Iteration 107
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 107: Reward -51.387 Loss 47174.250 AE 0.046
Starting Iteration 108
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 108: Reward -52.443 Loss 35868.887 AE 0.046
Starting Iteration 109
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 109: Reward -56.715 Loss 83408.914 AE 0.047
Starting Iteration 110
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 110: Reward -55.096 Loss 50331.098 AE 0.046
Starting Iteration 111
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 111: Reward -59.163 Loss 45080.254 AE 0.046
Starting Iteration 112
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 112: Reward -54.512 Loss 38573.172 AE 0.045
Starting Iteration 113
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 113: Reward -51.001 Loss 37370.250 AE 0.043
Starting Iteration 114
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 114: Reward -47.739 Loss 31931.072 AE 0.042
Starting Iteration 115
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 115: Reward -53.125 Loss 34741.820 AE 0.042
Starting Iteration 116
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 116: Reward -46.797 Loss 28624.303 AE 0.042
Starting Iteration 117
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 117: Reward -52.397 Loss 33915.266 AE 0.043
Starting Iteration 118
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 118: Reward -49.320 Loss 34026.750 AE 0.042
Starting Iteration 119
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 119: Reward -54.114 Loss 48082.594 AE 0.044
Starting Iteration 120
  Step 0/20
  Computing Advantages...