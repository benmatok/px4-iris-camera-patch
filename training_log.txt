WarpDrive not installed or not fully importable (likely missing pycuda). Using custom CPU trainer.
WARNING: CUDA or WarpDrive not available. Falling back to Custom CPU Training.
CPU Mode: Reduced agents to 200 and iterations to 5000
Starting Iteration 0
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 0: Reward -216.350 Loss 5082641.000 AE 0.120
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 1
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 1: Reward -240.121 Loss 6940728.000 AE 0.112
Starting Iteration 2
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 2: Reward -212.873 Loss 5367536.000 AE 0.104
Starting Iteration 3
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 3: Reward -241.413 Loss 6970947.500 AE 0.097
Starting Iteration 4
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 4: Reward -206.474 Loss 5045375.500 AE 0.088
Starting Iteration 5
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 5: Reward -213.792 Loss 5193692.000 AE 0.081
Starting Iteration 6
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 6: Reward -200.440 Loss 4942800.500 AE 0.078
Starting Iteration 7
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 7: Reward -212.143 Loss 5598601.500 AE 0.078
Starting Iteration 8
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 8: Reward -210.329 Loss 6115998.500 AE 0.075
Starting Iteration 9
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 9: Reward -193.922 Loss 5227386.000 AE 0.068
Starting Iteration 10
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 10: Reward -218.042 Loss 7154026.500 AE 0.063
Starting Iteration 11
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 11: Reward -190.280 Loss 6479594.000 AE 0.057
Starting Iteration 12
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 12: Reward -229.952 Loss 7558185.000 AE 0.055
Starting Iteration 13
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 13: Reward -200.481 Loss 6355409.000 AE 0.051
Starting Iteration 14
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 14: Reward -190.283 Loss 5169155.500 AE 0.048
Starting Iteration 15
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 15: Reward -202.569 Loss 6006430.500 AE 0.047
Starting Iteration 16
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 16: Reward -232.881 Loss 8157030.500 AE 0.046
Starting Iteration 17
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 17: Reward -207.846 Loss 7636925.000 AE 0.046
Starting Iteration 18
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 18: Reward -198.685 Loss 6598812.500 AE 0.044
Starting Iteration 19
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 19: Reward -205.525 Loss 8023816.000 AE 0.044
Starting Iteration 20
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 20: Reward -194.009 Loss 6675232.500 AE 0.041
Starting Iteration 21
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 21: Reward -189.829 Loss 6171849.500 AE 0.039
Starting Iteration 22
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 22: Reward -176.727 Loss 5220144.500 AE 0.038
Starting Iteration 23
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 23: Reward -183.790 Loss 5416192.000 AE 0.037
Starting Iteration 24
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 24: Reward -219.887 Loss 10021609.000 AE 0.037
Starting Iteration 25
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 25: Reward -216.077 Loss 9534646.000 AE 0.038
Starting Iteration 26
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 26: Reward -241.759 Loss 13061954.000 AE 0.038
Starting Iteration 27
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 27: Reward -246.598 Loss 13964342.000 AE 0.038
Starting Iteration 28
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 28: Reward -259.226 Loss 14935911.000 AE 0.036
Starting Iteration 29
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 29: Reward -244.117 Loss 13099418.000 AE 0.037
Starting Iteration 30
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 30: Reward -257.352 Loss 12451147.000 AE 0.037
Starting Iteration 31
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 31: Reward -261.223 Loss 13673222.000 AE 0.037
Starting Iteration 32
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 32: Reward -293.023 Loss 16963376.000 AE 0.037
Starting Iteration 33
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 33: Reward -282.296 Loss 16763941.000 AE 0.034
Starting Iteration 34
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 34: Reward -204.831 Loss 8377976.500 AE 0.037
Starting Iteration 35
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 35: Reward -85.180 Loss 665226.000 AE 0.040
Starting Iteration 36
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 36: Reward -67.977 Loss 483038.219 AE 0.046
Starting Iteration 37
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 37: Reward -66.317 Loss 574766.188 AE 0.053
Starting Iteration 38
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 38: Reward -53.624 Loss 162576.875 AE 0.057
Starting Iteration 39
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 39: Reward -55.652 Loss 159335.047 AE 0.062
Starting Iteration 40
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 40: Reward -51.904 Loss 144252.312 AE 0.066
Starting Iteration 41
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 41: Reward -57.356 Loss 147035.172 AE 0.067
Starting Iteration 42
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 42: Reward -55.321 Loss 140861.125 AE 0.067
Starting Iteration 43
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 43: Reward -53.573 Loss 306158.062 AE 0.068
Starting Iteration 44
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 44: Reward -51.452 Loss 114042.789 AE 0.068
Starting Iteration 45
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 45: Reward -50.279 Loss 101743.742 AE 0.068
Starting Iteration 46
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 46: Reward -53.616 Loss 118012.812 AE 0.068
Starting Iteration 47
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 47: Reward -51.303 Loss 142484.719 AE 0.067
Starting Iteration 48
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 48: Reward -51.669 Loss 100988.750 AE 0.067
Starting Iteration 49
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 49: Reward -53.790 Loss 120701.734 AE 0.067
Starting Iteration 50
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 50: Reward -47.666 Loss 97698.852 AE 0.067
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 51
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 51: Reward -52.292 Loss 95662.320 AE 0.066
Starting Iteration 52
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 52: Reward -54.334 Loss 138605.906 AE 0.066
Starting Iteration 53
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 53: Reward -52.558 Loss 110692.570 AE 0.066
Starting Iteration 54
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 54: Reward -55.396 Loss 141670.000 AE 0.065
Starting Iteration 55
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 55: Reward -54.124 Loss 163418.500 AE 0.065
Starting Iteration 56
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 56: Reward -45.475 Loss 81636.070 AE 0.065
Starting Iteration 57
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 57: Reward -54.348 Loss 117968.711 AE 0.065
Starting Iteration 58
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 58: Reward -52.888 Loss 123573.086 AE 0.065
Starting Iteration 59
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 59: Reward -54.577 Loss 111222.141 AE 0.064
Starting Iteration 60
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 60: Reward -52.440 Loss 134794.938 AE 0.064
Starting Iteration 61
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 61: Reward -54.657 Loss 105088.680 AE 0.064
Starting Iteration 62
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 62: Reward -51.093 Loss 118260.195 AE 0.064
Starting Iteration 63
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 63: Reward -52.645 Loss 227353.219 AE 0.063
Starting Iteration 64
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 64: Reward -48.074 Loss 84213.398 AE 0.064
Starting Iteration 65
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 65: Reward -53.040 Loss 112172.078 AE 0.063
Starting Iteration 66
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 66: Reward -52.561 Loss 104587.062 AE 0.063
Starting Iteration 67
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 67: Reward -52.254 Loss 98294.711 AE 0.063
Starting Iteration 68
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 68: Reward -52.142 Loss 93189.562 AE 0.062
Starting Iteration 69
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 69: Reward -56.824 Loss 122718.141 AE 0.062
Starting Iteration 70
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 70: Reward -51.329 Loss 88079.734 AE 0.062
Starting Iteration 71
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 71: Reward -50.215 Loss 84326.820 AE 0.062
Starting Iteration 72
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 72: Reward -49.384 Loss 108021.227 AE 0.060
Starting Iteration 73
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 73: Reward -52.025 Loss 188231.922 AE 0.060
Starting Iteration 74
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 74: Reward -53.437 Loss 109388.289 AE 0.061
Starting Iteration 75
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 75: Reward -54.959 Loss 121971.992 AE 0.062
Starting Iteration 76
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 76: Reward -51.330 Loss 110871.234 AE 0.061
Starting Iteration 77
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 77: Reward -45.615 Loss 80885.969 AE 0.061
Starting Iteration 78
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 78: Reward -50.002 Loss 144900.953 AE 0.061
Starting Iteration 79
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 79: Reward -47.768 Loss 84401.758 AE 0.060
Starting Iteration 80
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 80: Reward -54.934 Loss 212926.109 AE 0.060
Starting Iteration 81
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 81: Reward -56.429 Loss 106404.773 AE 0.060
Starting Iteration 82
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 82: Reward -54.419 Loss 91218.320 AE 0.060
Starting Iteration 83
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 83: Reward -49.237 Loss 158832.016 AE 0.060
Starting Iteration 84
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 84: Reward -53.206 Loss 97700.633 AE 0.059
Starting Iteration 85
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 85: Reward -54.502 Loss 98645.727 AE 0.059
Starting Iteration 86
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 86: Reward -45.151 Loss 84047.195 AE 0.059
Starting Iteration 87
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 87: Reward -54.217 Loss 123498.875 AE 0.059
Starting Iteration 88
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 88: Reward -52.753 Loss 95741.945 AE 0.058
Starting Iteration 89
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 89: Reward -50.940 Loss 135646.078 AE 0.058
Starting Iteration 90
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 90: Reward -53.111 Loss 179935.625 AE 0.058
Starting Iteration 91
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 91: Reward -54.117 Loss 104463.789 AE 0.058
Starting Iteration 92
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 92: Reward -52.705 Loss 88274.383 AE 0.058
Starting Iteration 93
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 93: Reward -54.603 Loss 96395.023 AE 0.058
Starting Iteration 94
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 94: Reward -55.386 Loss 97084.906 AE 0.058
Starting Iteration 95
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 95: Reward -55.470 Loss 100114.984 AE 0.057
Starting Iteration 96
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 96: Reward -56.302 Loss 86851.961 AE 0.057
Starting Iteration 97
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 97: Reward -52.611 Loss 81731.859 AE 0.057
Starting Iteration 98
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 98: Reward -57.375 Loss 103362.602 AE 0.057
Starting Iteration 99
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 99: Reward -52.544 Loss 102824.570 AE 0.057
Starting Iteration 100
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 100: Reward -49.952 Loss 89826.797 AE 0.056
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 101
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 101: Reward -61.732 Loss 114492.445 AE 0.056
Starting Iteration 102
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 102: Reward -50.032 Loss 80042.367 AE 0.056
Starting Iteration 103
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 103: Reward -45.410 Loss 66932.266 AE 0.057
Starting Iteration 104
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 104: Reward -58.544 Loss 170798.016 AE 0.057
Starting Iteration 105
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 105: Reward -59.850 Loss 116751.477 AE 0.056
Starting Iteration 106
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 106: Reward -47.804 Loss 65059.871 AE 0.056
Starting Iteration 107
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 107: Reward -54.079 Loss 83315.711 AE 0.055
Starting Iteration 108
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 108: Reward -50.145 Loss 78237.883 AE 0.055
Starting Iteration 109
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 109: Reward -46.664 Loss 76692.562 AE 0.055
Starting Iteration 110
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 110: Reward -51.750 Loss 90122.438 AE 0.056
Starting Iteration 111
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 111: Reward -50.193 Loss 79880.875 AE 0.055
Starting Iteration 112
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 112: Reward -55.589 Loss 92806.844 AE 0.055
Starting Iteration 113
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 113: Reward -52.252 Loss 86966.453 AE 0.055
Starting Iteration 114
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 114: Reward -53.628 Loss 88102.172 AE 0.055
Starting Iteration 115
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 115: Reward -53.134 Loss 101839.312 AE 0.055
Starting Iteration 116
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 116: Reward -49.193 Loss 68738.805 AE 0.054
Starting Iteration 117
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 117: Reward -49.418 Loss 61107.633 AE 0.055
Starting Iteration 118
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 118: Reward -58.680 Loss 233689.344 AE 0.054
Starting Iteration 119
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 119: Reward -48.095 Loss 68179.688 AE 0.054
Starting Iteration 120
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 120: Reward -55.284 Loss 115972.094 AE 0.054
Starting Iteration 121
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 121: Reward -56.238 Loss 120392.680 AE 0.054
Starting Iteration 122
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 122: Reward -58.744 Loss 276046.969 AE 0.055
Starting Iteration 123
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 123: Reward -52.076 Loss 82476.727 AE 0.054
Starting Iteration 124
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 124: Reward -55.019 Loss 92214.867 AE 0.054
Starting Iteration 125
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 125: Reward -53.040 Loss 81849.805 AE 0.054
Starting Iteration 126
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 126: Reward -50.030 Loss 85139.047 AE 0.054
Starting Iteration 127
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 127: Reward -56.209 Loss 103091.398 AE 0.054
Starting Iteration 128
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 128: Reward -48.896 Loss 70733.883 AE 0.053
Starting Iteration 129
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 129: Reward -51.367 Loss 69224.812 AE 0.053
Starting Iteration 130
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 130: Reward -51.573 Loss 71709.219 AE 0.053
Starting Iteration 131
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 131: Reward -49.221 Loss 71398.023 AE 0.053
Starting Iteration 132
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 132: Reward -48.856 Loss 74051.898 AE 0.053
Starting Iteration 133
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 133: Reward -49.009 Loss 65693.258 AE 0.053
Starting Iteration 134
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 134: Reward -52.827 Loss 74910.508 AE 0.054
Starting Iteration 135
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 135: Reward -50.209 Loss 65745.281 AE 0.053
Starting Iteration 136
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 136: Reward -46.815 Loss 69982.289 AE 0.053
Starting Iteration 137
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 137: Reward -46.863 Loss 66031.508 AE 0.054
Starting Iteration 138
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 138: Reward -57.464 Loss 88129.688 AE 0.053
Starting Iteration 139
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 139: Reward -50.726 Loss 91682.930 AE 0.052
Starting Iteration 140
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 140: Reward -53.824 Loss 80672.195 AE 0.053
Starting Iteration 141
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 141: Reward -55.784 Loss 92976.188 AE 0.053
Starting Iteration 142
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 142: Reward -49.756 Loss 76289.758 AE 0.053
Starting Iteration 143
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 143: Reward -58.655 Loss 105244.586 AE 0.052
Starting Iteration 144
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 144: Reward -50.696 Loss 72266.844 AE 0.053
Starting Iteration 145
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 145: Reward -50.212 Loss 75713.227 AE 0.052
Starting Iteration 146
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 146: Reward -52.315 Loss 80413.547 AE 0.053
Starting Iteration 147
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 147: Reward -51.189 Loss 74851.438 AE 0.052
Starting Iteration 148
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 148: Reward -53.382 Loss 86790.758 AE 0.052
Starting Iteration 149
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 149: Reward -55.623 Loss 90779.180 AE 0.052
Starting Iteration 150
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 150: Reward -60.108 Loss 147443.109 AE 0.052
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 151
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 151: Reward -59.265 Loss 141922.000 AE 0.052
Starting Iteration 152
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 152: Reward -46.458 Loss 72556.875 AE 0.052
Starting Iteration 153
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 153: Reward -49.326 Loss 64643.914 AE 0.052
Starting Iteration 154
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 154: Reward -48.120 Loss 58364.000 AE 0.052
Starting Iteration 155
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 155: Reward -49.418 Loss 70055.984 AE 0.052
Starting Iteration 156
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 156: Reward -55.752 Loss 88016.875 AE 0.052
Starting Iteration 157
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 157: Reward -49.089 Loss 66720.180 AE 0.052
Starting Iteration 158
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 158: Reward -48.469 Loss 72750.992 AE 0.052
Starting Iteration 159
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 159: Reward -51.437 Loss 77545.336 AE 0.052
Starting Iteration 160
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 160: Reward -57.770 Loss 141387.953 AE 0.052
Starting Iteration 161
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 161: Reward -51.947 Loss 70312.938 AE 0.052
Starting Iteration 162
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 162: Reward -50.251 Loss 70306.016 AE 0.052
Starting Iteration 163
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 163: Reward -54.520 Loss 107724.141 AE 0.051
Starting Iteration 164
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 164: Reward -47.191 Loss 61377.539 AE 0.052
Starting Iteration 165
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 165: Reward -51.540 Loss 123236.328 AE 0.052
Starting Iteration 166
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 166: Reward -48.886 Loss 126194.727 AE 0.052
Starting Iteration 167
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 167: Reward -50.038 Loss 66997.320 AE 0.052
Starting Iteration 168
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 168: Reward -52.532 Loss 69382.383 AE 0.052
Starting Iteration 169
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 169: Reward -54.659 Loss 70442.148 AE 0.051
Starting Iteration 170
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 170: Reward -49.535 Loss 68422.047 AE 0.052
Starting Iteration 171
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 171: Reward -57.549 Loss 118050.977 AE 0.052
Starting Iteration 172
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 172: Reward -59.463 Loss 93936.281 AE 0.052
Starting Iteration 173
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 173: Reward -52.765 Loss 181821.344 AE 0.052
Starting Iteration 174
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 174: Reward -54.690 Loss 152224.984 AE 0.051
Starting Iteration 175
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 175: Reward -42.809 Loss 52144.059 AE 0.052
Starting Iteration 176
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 176: Reward -47.622 Loss 64225.152 AE 0.052
Starting Iteration 177
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 177: Reward -50.482 Loss 70041.375 AE 0.052
Starting Iteration 178
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 178: Reward -49.909 Loss 76085.219 AE 0.051
Starting Iteration 179
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 179: Reward -58.718 Loss 96133.805 AE 0.051
Starting Iteration 180
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 180: Reward -48.996 Loss 71440.812 AE 0.051
Starting Iteration 181
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 181: Reward -58.505 Loss 107524.250 AE 0.051
Starting Iteration 182
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 182: Reward -54.788 Loss 76950.070 AE 0.052
Starting Iteration 183
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 183: Reward -51.523 Loss 66333.930 AE 0.052
Starting Iteration 184
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 184: Reward -50.339 Loss 72178.742 AE 0.051
Starting Iteration 185
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 185: Reward -48.796 Loss 61640.473 AE 0.051
Starting Iteration 186
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 186: Reward -48.701 Loss 55557.254 AE 0.051
Starting Iteration 187
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 187: Reward -46.782 Loss 61540.504 AE 0.051
Starting Iteration 188
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 188: Reward -57.641 Loss 91742.328 AE 0.051
Starting Iteration 189
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 189: Reward -49.946 Loss 61934.848 AE 0.051
Starting Iteration 190
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 190: Reward -54.803 Loss 80164.578 AE 0.051
Starting Iteration 191
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 191: Reward -52.135 Loss 70219.578 AE 0.051
Starting Iteration 192
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 192: Reward -51.534 Loss 71577.805 AE 0.051
Starting Iteration 193
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 193: Reward -50.464 Loss 71136.812 AE 0.051
Starting Iteration 194
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 194: Reward -56.760 Loss 163090.781 AE 0.051
Starting Iteration 195
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 195: Reward -55.630 Loss 92475.852 AE 0.051
Starting Iteration 196
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 196: Reward -52.935 Loss 70431.398 AE 0.051
Starting Iteration 197
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 197: Reward -53.212 Loss 73921.523 AE 0.052
Starting Iteration 198
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 198: Reward -52.060 Loss 75565.383 AE 0.051
Starting Iteration 199
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 199: Reward -57.751 Loss 91062.391 AE 0.051
Starting Iteration 200
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 200: Reward -58.407 Loss 80966.617 AE 0.052
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 201
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 201: Reward -53.410 Loss 87537.742 AE 0.051
Starting Iteration 202
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 202: Reward -50.055 Loss 58592.453 AE 0.051
Starting Iteration 203
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 203: Reward -48.976 Loss 86187.188 AE 0.051
Starting Iteration 204
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 204: Reward -55.616 Loss 90689.836 AE 0.051
Starting Iteration 205
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 205: Reward -53.385 Loss 84025.422 AE 0.051
Starting Iteration 206
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 206: Reward -47.716 Loss 63952.043 AE 0.051
Starting Iteration 207
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 207: Reward -52.351 Loss 72047.430 AE 0.051
Starting Iteration 208
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 208: Reward -57.527 Loss 90279.852 AE 0.051
Starting Iteration 209
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 209: Reward -48.488 Loss 73057.320 AE 0.051
Starting Iteration 210
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 210: Reward -53.933 Loss 84845.141 AE 0.051
Starting Iteration 211
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 211: Reward -44.448 Loss 58376.602 AE 0.051
Starting Iteration 212
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 212: Reward -50.418 Loss 77274.742 AE 0.051
Starting Iteration 213
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 213: Reward -54.431 Loss 76542.172 AE 0.051
Starting Iteration 214
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 214: Reward -56.150 Loss 82833.445 AE 0.051
Starting Iteration 215
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 215: Reward -55.162 Loss 156951.906 AE 0.052
Starting Iteration 216
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 216: Reward -50.290 Loss 74718.117 AE 0.051
Starting Iteration 217
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 217: Reward -52.688 Loss 70256.602 AE 0.051
Starting Iteration 218
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 218: Reward -50.788 Loss 59374.008 AE 0.051
Starting Iteration 219
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 219: Reward -50.897 Loss 61977.945 AE 0.051
Starting Iteration 220
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 220: Reward -51.018 Loss 68942.367 AE 0.051
Starting Iteration 221
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 221: Reward -49.174 Loss 56355.688 AE 0.051
Starting Iteration 222
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 222: Reward -57.668 Loss 102587.141 AE 0.051
Starting Iteration 223
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 223: Reward -49.954 Loss 65569.648 AE 0.051
Starting Iteration 224
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 224: Reward -50.365 Loss 64920.230 AE 0.051
Starting Iteration 225
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 225: Reward -47.674 Loss 56990.855 AE 0.051
Starting Iteration 226
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 226: Reward -54.524 Loss 75529.258 AE 0.051
Starting Iteration 227
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 227: Reward -55.376 Loss 80918.445 AE 0.050
Starting Iteration 228
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 228: Reward -48.621 Loss 79093.883 AE 0.051
Starting Iteration 229
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 229: Reward -58.697 Loss 76866.562 AE 0.050
Starting Iteration 230
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 230: Reward -53.588 Loss 65475.230 AE 0.051
Starting Iteration 231
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 231: Reward -48.737 Loss 58483.871 AE 0.051
Starting Iteration 232
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 232: Reward -54.577 Loss 76402.031 AE 0.051
Starting Iteration 233
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 233: Reward -50.912 Loss 59576.195 AE 0.051
Starting Iteration 234
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 234: Reward -57.889 Loss 117306.172 AE 0.051
Starting Iteration 235
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 235: Reward -52.415 Loss 62576.543 AE 0.051
Starting Iteration 236
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 236: Reward -48.181 Loss 68776.719 AE 0.051
Starting Iteration 237
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 237: Reward -50.663 Loss 59212.617 AE 0.051
Starting Iteration 238
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 238: Reward -57.165 Loss 71419.500 AE 0.051
Starting Iteration 239
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 239: Reward -56.918 Loss 87530.992 AE 0.051
Starting Iteration 240
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 240: Reward -53.395 Loss 77558.758 AE 0.051
Starting Iteration 241
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 241: Reward -52.392 Loss 74962.547 AE 0.051
Starting Iteration 242
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 242: Reward -61.899 Loss 125462.453 AE 0.051
Starting Iteration 243
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 243: Reward -54.152 Loss 69185.961 AE 0.051
Starting Iteration 244
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 244: Reward -51.824 Loss 68296.281 AE 0.051
Starting Iteration 245
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 245: Reward -52.302 Loss 64526.570 AE 0.051
Starting Iteration 246
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 246: Reward -51.476 Loss 79690.914 AE 0.050
Starting Iteration 247
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 247: Reward -51.687 Loss 67329.367 AE 0.050
Starting Iteration 248
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 248: Reward -52.672 Loss 70998.469 AE 0.051
Starting Iteration 249
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 249: Reward -49.700 Loss 59470.039 AE 0.051
Starting Iteration 250
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 250: Reward -50.722 Loss 58220.332 AE 0.051
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 251
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 251: Reward -51.267 Loss 63004.105 AE 0.051
Starting Iteration 252
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 252: Reward -54.208 Loss 71509.445 AE 0.051
Starting Iteration 253
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 253: Reward -50.228 Loss 54884.273 AE 0.051
Starting Iteration 254
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 254: Reward -51.872 Loss 67864.820 AE 0.051
Starting Iteration 255
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 255: Reward -53.735 Loss 64918.980 AE 0.050
Starting Iteration 256
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 256: Reward -51.912 Loss 76295.477 AE 0.050
Starting Iteration 257
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 257: Reward -55.981 Loss 67214.070 AE 0.051
Starting Iteration 258
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 258: Reward -52.184 Loss 65962.602 AE 0.051
Starting Iteration 259
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 259: Reward -55.682 Loss 105668.719 AE 0.050
Starting Iteration 260
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 260: Reward -53.759 Loss 62249.953 AE 0.051
Starting Iteration 261
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 261: Reward -54.243 Loss 65775.836 AE 0.051
Starting Iteration 262
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 262: Reward -50.551 Loss 61693.559 AE 0.051
Starting Iteration 263
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 263: Reward -50.269 Loss 65115.016 AE 0.050
Starting Iteration 264
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 264: Reward -52.454 Loss 62830.934 AE 0.050
Starting Iteration 265
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 265: Reward -45.901 Loss 51045.043 AE 0.051
Starting Iteration 266
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 266: Reward -51.096 Loss 59247.621 AE 0.051
Starting Iteration 267
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 267: Reward -54.026 Loss 62072.027 AE 0.051
Starting Iteration 268
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 268: Reward -50.857 Loss 61035.320 AE 0.051
Starting Iteration 269
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 269: Reward -49.571 Loss 74413.250 AE 0.051
Starting Iteration 270
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 270: Reward -53.398 Loss 73904.312 AE 0.051
Starting Iteration 271
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 271: Reward -50.084 Loss 74511.461 AE 0.051
Starting Iteration 272
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 272: Reward -52.336 Loss 66008.953 AE 0.051
Starting Iteration 273
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 273: Reward -55.196 Loss 92372.867 AE 0.051
Starting Iteration 274
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 274: Reward -54.646 Loss 77267.211 AE 0.050
Starting Iteration 275
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 275: Reward -49.345 Loss 70762.086 AE 0.051
Starting Iteration 276
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 276: Reward -53.532 Loss 72502.914 AE 0.050
Starting Iteration 277
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 277: Reward -51.608 Loss 66292.516 AE 0.050
Starting Iteration 278
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 278: Reward -53.362 Loss 55942.469 AE 0.051
Starting Iteration 279
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 279: Reward -57.370 Loss 161308.625 AE 0.051
Starting Iteration 280
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 280: Reward -55.476 Loss 82349.500 AE 0.051
Starting Iteration 281
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 281: Reward -50.334 Loss 68511.016 AE 0.051
Starting Iteration 282
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 282: Reward -52.471 Loss 63440.336 AE 0.051
Starting Iteration 283
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 283: Reward -55.136 Loss 69755.141 AE 0.051
Starting Iteration 284
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 284: Reward -52.312 Loss 65776.961 AE 0.051
Starting Iteration 285
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 285: Reward -52.086 Loss 54411.359 AE 0.050
Starting Iteration 286
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 286: Reward -52.568 Loss 66475.750 AE 0.050
Starting Iteration 287
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 287: Reward -54.832 Loss 76903.594 AE 0.051
Starting Iteration 288
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 288: Reward -54.829 Loss 144702.438 AE 0.051
Starting Iteration 289
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 289: Reward -54.634 Loss 75514.781 AE 0.050
Starting Iteration 290
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 290: Reward -56.127 Loss 68109.922 AE 0.051
Starting Iteration 291
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 291: Reward -52.132 Loss 54926.086 AE 0.051
Starting Iteration 292
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 292: Reward -47.065 Loss 66073.453 AE 0.050
Starting Iteration 293
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 293: Reward -44.879 Loss 48887.660 AE 0.051
Starting Iteration 294
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 294: Reward -50.787 Loss 55546.043 AE 0.050
Starting Iteration 295
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 295: Reward -48.258 Loss 49273.043 AE 0.050
Starting Iteration 296
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 296: Reward -51.898 Loss 69939.922 AE 0.051
Starting Iteration 297
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 297: Reward -51.147 Loss 60643.312 AE 0.051
Starting Iteration 298
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 298: Reward -52.376 Loss 91670.281 AE 0.050
Starting Iteration 299
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 299: Reward -49.844 Loss 49024.281 AE 0.050
Starting Iteration 300
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 300: Reward -46.885 Loss 61929.457 AE 0.050
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 301
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 301: Reward -55.366 Loss 56808.898 AE 0.051
Starting Iteration 302
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 302: Reward -48.571 Loss 54291.332 AE 0.051
Starting Iteration 303
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 303: Reward -53.291 Loss 56507.949 AE 0.051
Starting Iteration 304
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 304: Reward -52.953 Loss 57639.664 AE 0.050
Starting Iteration 305
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 305: Reward -53.347 Loss 58862.672 AE 0.050
Starting Iteration 306
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 306: Reward -54.559 Loss 64956.664 AE 0.050
Starting Iteration 307
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 307: Reward -48.317 Loss 160795.047 AE 0.051
Starting Iteration 308
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 308: Reward -49.431 Loss 57078.730 AE 0.051
Starting Iteration 309
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 309: Reward -54.043 Loss 71580.180 AE 0.050
Starting Iteration 310
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 310: Reward -48.403 Loss 45400.520 AE 0.051
Starting Iteration 311
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 311: Reward -58.959 Loss 98329.711 AE 0.050
Starting Iteration 312
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 312: Reward -50.426 Loss 75196.227 AE 0.050
Starting Iteration 313
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 313: Reward -50.735 Loss 50601.539 AE 0.051
Starting Iteration 314
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 314: Reward -54.237 Loss 114861.562 AE 0.051
Starting Iteration 315
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 315: Reward -59.497 Loss 78386.641 AE 0.050
Starting Iteration 316
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 316: Reward -55.183 Loss 63470.258 AE 0.050
Starting Iteration 317
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 317: Reward -44.100 Loss 53395.801 AE 0.050
Starting Iteration 318
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 318: Reward -53.835 Loss 275987.312 AE 0.051
Starting Iteration 319
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 319: Reward -49.241 Loss 49311.297 AE 0.050
Starting Iteration 320
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 320: Reward -48.464 Loss 49707.512 AE 0.051
Starting Iteration 321
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 321: Reward -50.853 Loss 55357.621 AE 0.050
Starting Iteration 322
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 322: Reward -51.052 Loss 57941.477 AE 0.050
Starting Iteration 323
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 323: Reward -50.639 Loss 60610.992 AE 0.051
Starting Iteration 324
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 324: Reward -58.073 Loss 59955.121 AE 0.050
Starting Iteration 325
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 325: Reward -47.873 Loss 54940.852 AE 0.050
Starting Iteration 326
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 326: Reward -53.196 Loss 61575.770 AE 0.050
Starting Iteration 327
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 327: Reward -47.662 Loss 45531.777 AE 0.051
Starting Iteration 328
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 328: Reward -49.268 Loss 57161.121 AE 0.050
Starting Iteration 329
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 329: Reward -54.137 Loss 73357.648 AE 0.050
Starting Iteration 330
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 330: Reward -45.618 Loss 46198.609 AE 0.050
Starting Iteration 331
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 331: Reward -52.150 Loss 54592.594 AE 0.050
Starting Iteration 332
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 332: Reward -46.340 Loss 47876.887 AE 0.051
Starting Iteration 333
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 333: Reward -51.281 Loss 92006.211 AE 0.050
Starting Iteration 334
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 334: Reward -54.338 Loss 50446.062 AE 0.051
Starting Iteration 335
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 335: Reward -47.230 Loss 48814.781 AE 0.050
Starting Iteration 336
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 336: Reward -47.937 Loss 46589.375 AE 0.050
Starting Iteration 337
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 337: Reward -49.907 Loss 54149.461 AE 0.050
Starting Iteration 338
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 338: Reward -51.507 Loss 54894.949 AE 0.050
Starting Iteration 339
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 339: Reward -50.749 Loss 54142.715 AE 0.050
Starting Iteration 340
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 340: Reward -45.407 Loss 38407.004 AE 0.050
Starting Iteration 341
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 341: Reward -47.723 Loss 53407.121 AE 0.050
Starting Iteration 342
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 342: Reward -56.002 Loss 66303.586 AE 0.050
Starting Iteration 343
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 343: Reward -44.268 Loss 45261.723 AE 0.050
Starting Iteration 344
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 344: Reward -50.142 Loss 56291.359 AE 0.050
Starting Iteration 345
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 345: Reward -50.915 Loss 52473.961 AE 0.051
Starting Iteration 346
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 346: Reward -50.020 Loss 43330.508 AE 0.050
Starting Iteration 347
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 347: Reward -54.249 Loss 47666.402 AE 0.050
Starting Iteration 348
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 348: Reward -51.586 Loss 79596.422 AE 0.051
Starting Iteration 349
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 349: Reward -51.803 Loss 56277.418 AE 0.050
Starting Iteration 350
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 350: Reward -48.800 Loss 54958.094 AE 0.049
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 351
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 351: Reward -51.136 Loss 51218.922 AE 0.050
Starting Iteration 352
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 352: Reward -51.818 Loss 61308.840 AE 0.050
Starting Iteration 353
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 353: Reward -49.566 Loss 61635.391 AE 0.050
Starting Iteration 354
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 354: Reward -48.581 Loss 47317.652 AE 0.050
Starting Iteration 355
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 355: Reward -48.839 Loss 50395.152 AE 0.050
Starting Iteration 356
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 356: Reward -53.423 Loss 51475.559 AE 0.050
Starting Iteration 357
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 357: Reward -46.957 Loss 43685.684 AE 0.050
Starting Iteration 358
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 358: Reward -51.266 Loss 56653.316 AE 0.050
Starting Iteration 359
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 359: Reward -53.948 Loss 70539.555 AE 0.050
Starting Iteration 360
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 360: Reward -54.072 Loss 55132.633 AE 0.050
Starting Iteration 361
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 361: Reward -52.507 Loss 63277.293 AE 0.050
Starting Iteration 362
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 362: Reward -51.043 Loss 53804.633 AE 0.050
Starting Iteration 363
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 363: Reward -43.800 Loss 38003.945 AE 0.050
Starting Iteration 364
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 364: Reward -53.129 Loss 78545.836 AE 0.050
Starting Iteration 365
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 365: Reward -55.078 Loss 73566.750 AE 0.049
Starting Iteration 366
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 366: Reward -54.433 Loss 53167.777 AE 0.050
Starting Iteration 367
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 367: Reward -52.232 Loss 48883.293 AE 0.050
Starting Iteration 368
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 368: Reward -59.126 Loss 78812.875 AE 0.050
Starting Iteration 369
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 369: Reward -51.409 Loss 52282.125 AE 0.050
Starting Iteration 370
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 370: Reward -50.480 Loss 54412.996 AE 0.050
Starting Iteration 371
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 371: Reward -54.260 Loss 53891.863 AE 0.050
Starting Iteration 372
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 372: Reward -51.565 Loss 60417.094 AE 0.050
Starting Iteration 373
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 373: Reward -53.619 Loss 61064.543 AE 0.050
Starting Iteration 374
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 374: Reward -48.603 Loss 65218.172 AE 0.050
Starting Iteration 375
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 375: Reward -55.142 Loss 91617.195 AE 0.050
Starting Iteration 376
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 376: Reward -53.559 Loss 54502.660 AE 0.050
Starting Iteration 377
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 377: Reward -52.494 Loss 54702.863 AE 0.050
Starting Iteration 378
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 378: Reward -54.452 Loss 58937.273 AE 0.050
Starting Iteration 379
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 379: Reward -54.496 Loss 77422.109 AE 0.050
Starting Iteration 380
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 380: Reward -55.612 Loss 69285.930 AE 0.050
Starting Iteration 381
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 381: Reward -47.825 Loss 50417.758 AE 0.050
Starting Iteration 382
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 382: Reward -54.022 Loss 57252.969 AE 0.049
Starting Iteration 383
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 383: Reward -50.095 Loss 61322.105 AE 0.050
Starting Iteration 384
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 384: Reward -49.301 Loss 40131.133 AE 0.049
Starting Iteration 385
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 385: Reward -44.295 Loss 34674.000 AE 0.050
Starting Iteration 386
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 386: Reward -51.034 Loss 53709.703 AE 0.049
Starting Iteration 387
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 387: Reward -51.757 Loss 45634.738 AE 0.050
Starting Iteration 388
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 388: Reward -52.876 Loss 45116.684 AE 0.049
Starting Iteration 389
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 389: Reward -51.802 Loss 60154.691 AE 0.049
Starting Iteration 390
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 390: Reward -51.339 Loss 73362.180 AE 0.050
Starting Iteration 391
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 391: Reward -50.022 Loss 52309.961 AE 0.049
Starting Iteration 392
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 392: Reward -48.974 Loss 47063.062 AE 0.050
Starting Iteration 393
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 393: Reward -53.801 Loss 78500.336 AE 0.049
Starting Iteration 394
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 394: Reward -47.384 Loss 46609.512 AE 0.050
Starting Iteration 395
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 395: Reward -48.979 Loss 46131.148 AE 0.049
Starting Iteration 396
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 396: Reward -45.482 Loss 37736.512 AE 0.050
Starting Iteration 397
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 397: Reward -44.873 Loss 41213.809 AE 0.049
Starting Iteration 398
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 398: Reward -51.521 Loss 45281.957 AE 0.050
Starting Iteration 399
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 399: Reward -46.436 Loss 41876.414 AE 0.050
Starting Iteration 400
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 400: Reward -56.633 Loss 59194.461 AE 0.049
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 401
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 401: Reward -49.942 Loss 59679.945 AE 0.049
Starting Iteration 402
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 402: Reward -46.975 Loss 48882.320 AE 0.049
Starting Iteration 403
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 403: Reward -49.747 Loss 54152.367 AE 0.049
Starting Iteration 404
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 404: Reward -53.234 Loss 69696.836 AE 0.048
Starting Iteration 405
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 405: Reward -55.823 Loss 292449.562 AE 0.049
Starting Iteration 406
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 406: Reward -56.749 Loss 97031.781 AE 0.049
Starting Iteration 407
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 407: Reward -53.574 Loss 43540.879 AE 0.048
Starting Iteration 408
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 408: Reward -52.771 Loss 51450.035 AE 0.049
Starting Iteration 409
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 409: Reward -49.385 Loss 41229.465 AE 0.048
Starting Iteration 410
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 410: Reward -52.511 Loss 82824.438 AE 0.049
Starting Iteration 411
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 411: Reward -57.000 Loss 75497.695 AE 0.049
Starting Iteration 412
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 412: Reward -56.695 Loss 93594.523 AE 0.049
Starting Iteration 413
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 413: Reward -51.196 Loss 52491.738 AE 0.049
Starting Iteration 414
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 414: Reward -52.996 Loss 42478.848 AE 0.049
Starting Iteration 415
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 415: Reward -51.485 Loss 45855.266 AE 0.049
Starting Iteration 416
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 416: Reward -50.540 Loss 49330.887 AE 0.049
Starting Iteration 417
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 417: Reward -54.868 Loss 51343.914 AE 0.048
Starting Iteration 418
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 418: Reward -49.736 Loss 48595.754 AE 0.049
Starting Iteration 419
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 419: Reward -58.285 Loss 59282.633 AE 0.049
Starting Iteration 420
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 420: Reward -52.957 Loss 55954.449 AE 0.048
Starting Iteration 421
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 421: Reward -50.318 Loss 63253.445 AE 0.047
Starting Iteration 422
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 422: Reward -50.242 Loss 44385.090 AE 0.048
Starting Iteration 423
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 423: Reward -55.792 Loss 61626.008 AE 0.047
Starting Iteration 424
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 424: Reward -54.144 Loss 63650.043 AE 0.047
Starting Iteration 425
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 425: Reward -50.838 Loss 269953.125 AE 0.048
Starting Iteration 426
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 426: Reward -54.591 Loss 52092.180 AE 0.047
Starting Iteration 427
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 427: Reward -51.581 Loss 54890.816 AE 0.048
Starting Iteration 428
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 428: Reward -54.103 Loss 52192.699 AE 0.047
Starting Iteration 429
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 429: Reward -50.395 Loss 68630.586 AE 0.048
Starting Iteration 430
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 430: Reward -49.636 Loss 49835.723 AE 0.048
Starting Iteration 431
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 431: Reward -55.132 Loss 86332.281 AE 0.048
Starting Iteration 432
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 432: Reward -54.684 Loss 52779.441 AE 0.048
Starting Iteration 433
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 433: Reward -49.400 Loss 46685.297 AE 0.049
Starting Iteration 434
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 434: Reward -55.399 Loss 57439.582 AE 0.049
Starting Iteration 435
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 435: Reward -56.168 Loss 53836.355 AE 0.049
Starting Iteration 436
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 436: Reward -55.806 Loss 127037.086 AE 0.049
Starting Iteration 437
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 437: Reward -53.689 Loss 46752.785 AE 0.049
Starting Iteration 438
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 438: Reward -46.650 Loss 39231.816 AE 0.050
Starting Iteration 439
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 439: Reward -52.799 Loss 49690.594 AE 0.049
Starting Iteration 440
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 440: Reward -44.058 Loss 31724.609 AE 0.050
Starting Iteration 441
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 441: Reward -53.054 Loss 53302.770 AE 0.049
Starting Iteration 442
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 442: Reward -58.548 Loss 50429.523 AE 0.050
Starting Iteration 443
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 443: Reward -49.188 Loss 52652.422 AE 0.049
Starting Iteration 444
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 444: Reward -50.743 Loss 43651.250 AE 0.049
Starting Iteration 445
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 445: Reward -45.163 Loss 33295.879 AE 0.049
Starting Iteration 446
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 446: Reward -55.029 Loss 99651.164 AE 0.049
Starting Iteration 447
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 447: Reward -56.639 Loss 56782.656 AE 0.049
Starting Iteration 448
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 448: Reward -51.378 Loss 52143.309 AE 0.049
Starting Iteration 449
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 449: Reward -54.661 Loss 53730.785 AE 0.050
Starting Iteration 450
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 450: Reward -54.627 Loss 53352.352 AE 0.050
Saved checkpoint to latest_checkpoint.pth
Visualization updated. GIF saved at visualizations/training_evolution.gif
Starting Iteration 451
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 451: Reward -46.764 Loss 47068.602 AE 0.049
Starting Iteration 452
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 452: Reward -50.755 Loss 54580.895 AE 0.050
Starting Iteration 453
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 453: Reward -54.547 Loss 53230.379 AE 0.049
Starting Iteration 454
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 454: Reward -49.062 Loss 41260.195 AE 0.049
Starting Iteration 455
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 455: Reward -45.885 Loss 36350.375 AE 0.050
Starting Iteration 456
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 456: Reward -47.748 Loss 38161.418 AE 0.049
Starting Iteration 457
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 457: Reward -53.440 Loss 55893.133 AE 0.050
Starting Iteration 458
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 458: Reward -51.494 Loss 267242.188 AE 0.050
Starting Iteration 459
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 459: Reward -45.504 Loss 38964.320 AE 0.049
Starting Iteration 460
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 460: Reward -55.861 Loss 65548.258 AE 0.049
Starting Iteration 461
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 461: Reward -52.500 Loss 48946.938 AE 0.049
Starting Iteration 462
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 462: Reward -50.789 Loss 43576.664 AE 0.049
Starting Iteration 463
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 463: Reward -57.648 Loss 63414.512 AE 0.049
Starting Iteration 464
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 464: Reward -56.534 Loss 52718.582 AE 0.049
Starting Iteration 465
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 465: Reward -48.375 Loss 36677.938 AE 0.049
Starting Iteration 466
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 466: Reward -53.591 Loss 132164.875 AE 0.049
Starting Iteration 467
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 467: Reward -50.238 Loss 46277.234 AE 0.049
Starting Iteration 468
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 468: Reward -52.730 Loss 47110.891 AE 0.049
Starting Iteration 469
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 469: Reward -48.822 Loss 40339.648 AE 0.049
Starting Iteration 470
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 470: Reward -46.105 Loss 49734.973 AE 0.049
Starting Iteration 471
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 471: Reward -47.677 Loss 40583.066 AE 0.049
Starting Iteration 472
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 472: Reward -56.308 Loss 49549.684 AE 0.049
Starting Iteration 473
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 473: Reward -55.457 Loss 50439.031 AE 0.049
Starting Iteration 474
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 474: Reward -59.134 Loss 58030.398 AE 0.049
Starting Iteration 475
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 475: Reward -56.944 Loss 55541.512 AE 0.049
Starting Iteration 476
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 476: Reward -47.301 Loss 44229.176 AE 0.049
Starting Iteration 477
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 477: Reward -49.628 Loss 51016.367 AE 0.049
Starting Iteration 478
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 478: Reward -54.492 Loss 52549.535 AE 0.049
Starting Iteration 479
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 479: Reward -54.582 Loss 70213.008 AE 0.049
Starting Iteration 480
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 480: Reward -50.109 Loss 52470.023 AE 0.049
Starting Iteration 481
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 481: Reward -52.519 Loss 44568.953 AE 0.049
Starting Iteration 482
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 482: Reward -51.964 Loss 58144.223 AE 0.049
Starting Iteration 483
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 483: Reward -49.053 Loss 47345.953 AE 0.049
Starting Iteration 484
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 484: Reward -56.463 Loss 50966.820 AE 0.049
Starting Iteration 485
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 485: Reward -49.410 Loss 64335.984 AE 0.049
Starting Iteration 486
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 486: Reward -50.476 Loss 44134.215 AE 0.049
Starting Iteration 487
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 487: Reward -57.271 Loss 156064.188 AE 0.050
Starting Iteration 488
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 488: Reward -50.874 Loss 200214.312 AE 0.050
Starting Iteration 489
  Step 0/20
  Computing Advantages...
  Updating Policy...
Iter 489: Reward -50.771 Loss 46597.156 AE 0.049
Starting Iteration 490
  Step 0/20
  Computing Advantages...
  Updating Policy...